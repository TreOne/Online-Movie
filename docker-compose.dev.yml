version: '3'

services:
  nginx:
    build: deploy/nginx
    volumes:
      - static_volume:/home/app/admin_panel/static
      - media_volume:/home/app/admin_panel/media
      - ./log/nginx:/var/log/nginx
    logging:
      driver: gelf  # default driver for docker is "json-file"
      options:
        gelf-address: udp://127.0.0.1:5045
        tag: nginx
    ports:
      - "80:80"
    depends_on:
      - admin_panel
      - api
      - auth_api
      - ugc_service
    networks:
      - movie_network
      - elk_logging

  admin_panel:
    build:
      context: .
      dockerfile: deploy/admin_panel/dev.Dockerfile
    volumes:
      - static_volume:/home/app/admin_panel/static
      - media_volume:/home/app/admin_panel/media
    env_file:
      - deploy/admin_panel/example.env
    depends_on:
      - db
    expose:
      - 8000
    networks:
      - movie_network
      - elk_logging

  db:
    image: postgres:12.0-alpine
    volumes:
      - postgres_data:/var/lib/postgresql/data/
      - ./deploy/db/sql_scripts/:/docker-entrypoint-initdb.d/
    ports:
      - "5432:5432"
    env_file:
      - deploy/db/example.env
    expose:
      - 5432
    networks:
      - movie_network

  redis:
    image: redis:6.2.6-alpine
    expose:
      - 6379
    ports:
      - "6379:6379"
    networks:
      - movie_network

  auth_api:
    build:
      context: .
      dockerfile: deploy/auth_api/dev.Dockerfile
    env_file:
      - deploy/auth_api/example.env
    expose:
      - 5000
    volumes:
      - ./src/auth_api:/app/auth_api
      - ./src/auth_api/migrations:/app/migrations
    depends_on:
      - authdb
      - authredis
    networks:
      - movie_network
      - elk_logging

  authdb:
    image: postgres:12.0-alpine
    volumes:
      - auth_postgres_data:/var/lib/postgresql/data/
    env_file:
      - deploy/auth_api/example.env
    expose:
      - 5432
    ports:
      - "15432:5432"
    networks:
      - movie_network

  authredis:
    image: redis:6.2.6-alpine
    expose:
      - 6379
    ports:
      - "16379:6379"
    networks:
      - movie_network

  elastic:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.1.2
    environment:
      cluster.name: movies-elasticsearch-cluster
      xpack.security.enabled: "false"
      bootstrap.memory_lock: "true"
      network.host: 0.0.0.0
      discovery.type: single-node
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    expose:
      - 9200
    ports:
      - "9200:9200"
    networks:
      - movie_network

  ps_to_es:
    build:
      context: .
      dockerfile: deploy/ps_to_es/Dockerfile
    env_file:
      - deploy/ps_to_es/example.env
    depends_on:
      - db
      - elastic
    networks:
      - movie_network

  api:
    build:
      context: .
      dockerfile: deploy/api/Dockerfile
    environment:
      PROJECT_NAME: movies
      REDIS_HOST: redis
      REDIS_PORT: 6379
      ELASTIC_HOST: http://elastic
      ELASTIC_PORT: 9200
    depends_on:
      - redis
      - elastic
    expose:
      - 8000
    networks:
      - movie_network

  ugc_service:
    build:
      context: .
      dockerfile: deploy/ugc_service/Dockerfile
    env_file:
      - deploy/ugc_service/example.env
    volumes:
      - ./src/ugc_service:/home/app/src
    depends_on:
      - kafka
    expose:
      - 8000
    ports:
      - "8000:8000"
    networks:
      - movie_network

  zookeeper-kafka:
    image: confluentinc/cp-zookeeper:6.2.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    expose:
      - 2181
    networks:
      - movie_network

  kf_to_ch:
    build:
      context: .
      dockerfile: deploy/kafka_to_clickhouse/Dockerfile
    volumes:
      - ./src/kafka_to_clickhouse:/home/app/etl
      - ./log/kf_to_ch:/var/log/app
    depends_on:
      - clickhouse
      - kafka
    networks:
      - movie_network

  kafka:
    image: confluentinc/cp-kafka:6.2.0
    expose:
      - 9092
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-kafka:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,HOST://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,HOST://localhost:9093
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper-kafka
    networks:
      - movie_network

  clickhouse:
    image: clickhouse/clickhouse-server
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    expose:
      - 8123
    ports:
      - "8123:8123"
    volumes:
      - clickhouse_data:/var/lib/clickhouse/
    networks:
      - movie_network

  ### ELK логирование
  logstash:
    image: logstash:8.1.2
    environment:
      XPACK_MONITORING_ENABLED: "true"  # Установите флаг 'false', если вы хотите запустить logstash без Elasticsearch, необходимо отключить встроенный мониторинг, отправляющий данные в ES
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
      ELASTICSEARCH_HOST: "elasticsearch:9200"
    ports:
      - "5044:5044/udp"
    volumes:
      # Монтируем файл с конфигурацией logstash
      - ./deploy/elk/logstash/logstash.conf:/config/logstash.conf:ro
      - ./log/nginx:/var/log/nginx:ro
    # Запускаем с указанием конфигурационного файла
    command: logstash -f /config/logstash.conf
    depends_on:
      - elasticsearch
    networks:
      - elk_logging

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.1.2
    volumes:
      - ./log/nginx:/var/log/nginx:ro
      - ./deploy/elk/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
    depends_on:
      - admin_panel
      - auth_api
      - nginx
      - logstash
      - elasticsearch
      - kibana_elk
    links:
      - logstash
    networks:
      - elk_logging

  elasticsearch:
    image: elasticsearch:8.1.2
    environment:
      xpack.security.enabled: "false"
      bootstrap.memory_lock: "true"
      network.host: 0.0.0.0
      discovery.type: single-node  # Указываем ES запуститься в одном экземпляре
    expose:
      - 9200
    ports:
      - "19200:9200"
    volumes:
      # Обратите внимание: не стоит использовать для ELK тот же ES, который задействован для полнотекстового поиска в вашем сервисе
      - elastic_elk_data:/tmp/elasticsearch/data
    networks:
      - elk_logging

  kibana_elk:
    image: kibana:8.1.2
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    ports:
      - "5602:5601"
    depends_on:
      - elasticsearch
    networks:
      - elk_logging

  ### Опциональные сервисы
  kibana:
    image: docker.elastic.co/kibana/kibana:8.1.2
    environment:
      ELASTICSEARCH_URL: http://elastic:9200
      ELASTICSEARCH_HOSTS: '["http://elastic:9200"]'
      SERVER_BASEPATH: /kibana
    depends_on:
      - elastic
    expose:
      - 5601
    networks:
      - movie_network

  jaeger:
    image: jaegertracing/all-in-one:latest
    expose:
      - 16686  # jaeger-ui
      - 6831  # udp
    ports:
      - "16686:16686"
      - "6831:6831"
    networks:
      - movie_network

volumes:
  postgres_data:
  auth_postgres_data:
  elastic_data:
  elastic_elk_data:
  zookeeper_data:
  clickhouse_data:
  static_volume:
  media_volume:

networks:
  movie_network:
    driver: bridge
  elk_logging:
    driver: bridge
